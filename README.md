Hi, Iâ€™m Fei Zhao! ðŸ‘‹

About Me

I am a Ph.D. candidate in Computer Science at The University of Alabama at Birmingham (UAB) with a 4.0 GPA, specializing in Multimodal Large Language Models (MLLMs), Parameter-Efficient Fine-Tuning (PEFT), Cross-Modal Generation, and Multimodal Fusion. With 14 years of experience in both research and engineering, I have published 16 papers (13 as the first author) in top-tier venues such as ACM CIKM, IEEE ICME, ACM SIGSPATIAL, and ACM Computing Surveys.

ðŸ”¬ Research & Projects
	â€¢	Mitigating Hallucinations in Vision-Language Models â€“ Developing reinforcement learning-based test-time adaptation to reduce hallucinations in multimodal models.
	â€¢	CheckGuard â€“ Created a large-scale cross-modal dataset for stolen check detection and information extraction using Vision-Language Models (VLMs).
	â€¢	Remote Sensing & Disaster Assessment â€“ Designed a visual prompt learning approach for post-disaster damage evaluation, surpassing state-of-the-art methods.
	â€¢	AI for Election Security â€“ Built a Siamese Transformer-based model for ballot fraud detection, contributing to a $1.2M NSF grant.

ðŸŒ± Currently Working on	
  â€¢	Vision-Language Models Hallucination Mitigation
  â€¢	Vision-Language Models chain of Thought (CoT) 
	â€¢	Advanced Deep Multimodal Data Fusion techniques
	â€¢	Efficient adaptation of Vision-Language Models

ðŸ“« Contact Me
	â€¢	Email: larry5@uab.edu
	â€¢	LinkedIn: linkedin.com/in/fei-zhao-6a762724a
	â€¢	Website: feizhao19.github.io/publications

âš¡ Philosophy

Trainable. Coachable. Hungry.

This version aligns with your expertise while keeping it engaging and structured. Let me know if youâ€™d like any adjustments! ðŸš€
